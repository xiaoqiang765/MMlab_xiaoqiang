{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9323e8-b0f8-44b1-86fe-e0ac71034c96",
   "metadata": {},
   "source": [
    "## 分割COCO类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac82f881-b440-47bb-90e8-36255fef67e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e9d0ff0-b465-447d-8f68-c09390ef2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(img_dir, ann_file, output_dir, val_ratio=0.2):\n",
    "    \"\"\"\n",
    "    split coco dataset into train_dataset and val_dataset\n",
    "    -- dataset\n",
    "      -- images\n",
    "      -- annotations\n",
    "    \"\"\"\n",
    "    # 创建输出目录\n",
    "    train_dir = os.path.join(output_dir, 'train_images')\n",
    "    val_dir = os.path.join(output_dir, 'val_images')\n",
    "    ann_dir = os.path.join(output_dir, 'annotations')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(ann_dir, exist_ok=True)\n",
    "\n",
    "    # 读取coco_dataset标注文件并获取images与annotations数据\n",
    "    with open(ann_file, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    images = coco_data['images']\n",
    "    annotations = coco_data['annotations']\n",
    "\n",
    "    # 分割数据集并copy图片\n",
    "    random.shuffle(images)\n",
    "    val_size = int(len(images) * val_ratio)\n",
    "    train_images = images[val_size:]\n",
    "    val_images = images[:val_size]\n",
    "    for image in tqdm(train_images, desc='copy train_images', total=len(train_images)):\n",
    "        image_path = os.path.join(img_dir, image['file_name'])\n",
    "        shutil.copy(image_path, train_dir)\n",
    "    for image in tqdm(val_images, desc='copy val_images', total=len(val_images)):\n",
    "        image_path = os.path.join(img_dir, image['file_name'])\n",
    "        shutil.copy(image_path, val_dir)\n",
    "\n",
    "    # 分割annotations\n",
    "    train_annotations = [annotation for annotation in tqdm(annotations, desc='filter train_annotations', total=len(annotations)) \\\n",
    "                         if annotation['image_id'] in [image['id'] for image in train_images]]\n",
    "    val_annotations = [annotation for annotation in tqdm(annotations, desc='filter val_annotations', total=len(annotations)) \\\n",
    "                         if annotation['image_id'] in [image['id'] for image in val_images]]\n",
    "    \n",
    "    # 更新训练集图像与注释字段并保存\n",
    "    coco_data['images'] = train_images\n",
    "    coco_data['annotations'] = train_annotations\n",
    "    coco_data['info']['description'] = 'train dataset'\n",
    "    train_json_file = os.path.join(ann_dir, 'data_train.json')\n",
    "    with open(train_json_file, 'w') as f:\n",
    "        json.dump(coco_data, f)\n",
    "    # 更新验证集图像与标注信息字段并保存\n",
    "    coco_data['images'] = val_images\n",
    "    coco_data['annotations'] = val_annotations\n",
    "    coco_data['info']['description'] = 'val dataset'\n",
    "    train_json_file = os.path.join(ann_dir, 'data_val.json')\n",
    "    with open(train_json_file, 'w') as f:\n",
    "        json.dump(coco_data, f)\n",
    "    print('Dataset split down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76b447c2-e19a-465e-98eb-9251a7a4dc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "copy train_images:   0%|                                | 0/228 [00:00<?, ?it/s]\u001b[A\n",
      "copy train_images:  23%|█████                 | 52/228 [00:00<00:00, 513.76it/s]\u001b[A\n",
      "copy train_images:  54%|███████████▎         | 123/228 [00:00<00:00, 626.73it/s]\u001b[A\n",
      "copy train_images: 100%|█████████████████████| 228/228 [00:00<00:00, 646.67it/s]\u001b[A\n",
      "\n",
      "copy val_images: 100%|█████████████████████████| 56/56 [00:00<00:00, 727.13it/s]\u001b[A\n",
      "\n",
      "filter train_annotations: 100%|█████████| 1256/1256 [00:00<00:00, 141904.05it/s]\u001b[A\n",
      "\n",
      "filter val_annotations: 100%|███████████| 1256/1256 [00:00<00:00, 498019.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "img_dir = '/Users/xiaoqiang/Mlearning/dataset/Drink_coco/images'\n",
    "ann_file = '/Users/xiaoqiang/Mlearning/dataset/Drink_coco/annotations/instances.json'\n",
    "output_dir = '/Users/xiaoqiang/Mlearning/dataset/Drink_coco'\n",
    "split_dataset(img_dir=img_dir, ann_file=ann_file, output_dir=output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e5b2ca-20bd-4f34-a822-57371cfddef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmlab2",
   "language": "python",
   "name": "mmlab2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
